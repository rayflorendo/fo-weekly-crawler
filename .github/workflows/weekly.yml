# .github/workflows/weekly.yml
name: weekly-crawl

on:
  schedule:
    - cron: '0 18 * * 5'   # JST åœŸæ›œ 03:00 ã«è‡ªå‹•å®Ÿè¡Œ
  workflow_dispatch:       # Actions ã‹ã‚‰æ‰‹å‹•å®Ÿè¡Œ

permissions:
  contents: write

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0                # push å‘¨ã‚Šã®ä¸å…·åˆã‚’é¿ã‘ã‚‹
          persist-credentials: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: pip install -r requirements.txt

      - name: Run scraper
        run: python scrape.py

      - name: Sanity check (optional but helpful)
        shell: bash
        run: |
          set -e
          test -f docs/data.json || (echo "âŒ docs/data.json ãŒã‚ã‚Šã¾ã›ã‚“" && exit 1)
          size=$(wc -c < docs/data.json | tr -d ' ')
          echo "ğŸ“„ docs/data.json size: ${size} bytes"

      # ã“ã“ã§ã€Œå·®åˆ†ãŒãªãã¦ã‚‚ã‚³ãƒŸãƒƒãƒˆã€ã‚’å¼·åˆ¶ã™ã‚‹
      - name: Commit & push (even if no diff)
        shell: bash
        run: |
          set -e
          git config user.name  "auto-bot"
          git config user.email "bot@example.com"

          # ã¾ãšé€šå¸¸ã®å¤‰æ›´ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸
          git add docs/data.json docs/data.jsonl || true

          if git diff --cached --quiet; then
            echo "âš ï¸ å¤‰åŒ–ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸãŒã€æ›´æ–°æ‰±ã„ã®ç©ºã‚³ãƒŸãƒƒãƒˆã‚’ä½œã‚Šã¾ã™"
            git commit --allow-empty -m "chore: weekly refresh (no content change)"
          else
            git commit -m "chore: weekly data.json update"
          fi

          # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒã¸æ˜ç¤ºçš„ã« pushï¼ˆæ‰‹å‹•å®Ÿè¡Œã§ã‚‚å®‰å…¨ï¼‰
          git push origin HEAD:${GITHUB_REF_NAME:-main}
